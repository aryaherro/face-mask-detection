{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44JRqlK3IyFv"
      },
      "source": [
        "# **Face Mask Detection**\n",
        "\n",
        "Program Machine Learning untuk mendeteksi penggunaan masker. Program dibuat menggunakan metode CNN dengan arsitektur VGG16Net ditambahkan model deteksi wajah ResNet-10 dan MTCNN.\n",
        "\n",
        "**ini merupakan edit dari** https://colab.research.google.com/github/Soedirman-Machine-Learning/face-mask-detection/blob/main/Full_Face_Mask_Detection_VGG16Net.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3ph4kTgu8UN"
      },
      "source": [
        "## Tahap Awal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGAocb4i3q_R",
        "outputId": "0f2adb1b-7470-40dd-9382-6b7886aa2437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'face-mask-detection'...\n",
            "remote: Enumerating objects: 4756, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "^C\n",
            "[Errno 2] No such file or directory: 'face-mask-detection'\n",
            "/content\n",
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "# Melakukan cloning data\n",
        "!git clone https://github.com/aryaherro/face-mask-detection.git\n",
        "\n",
        "# Berpindah ke folder face-mask-detection\n",
        "%cd face-mask-detection\n",
        "\n",
        "# Memeriksa isi folder face-mask-detection\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnqMpfEwL_Zp"
      },
      "source": [
        "pengujian model dengan menggunakan res10_300x300_ssd_iter_140000.caffemodel dan deploy.prototxt untuk mendeteksi bagian wajah"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvjSZ30YhWh"
      },
      "source": [
        "## Mengimpor *Library*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "W3Za-KOKf-Ot",
        "outputId": "232f8f7f-6a8d-433c-bd61-563aab56c6c1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-10355eda7061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAveragePooling2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexperimental\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterpreter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpHint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauthoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyzer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelAnalyzer\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mAnalyzer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpResolverType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthoring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthoring\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_print_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/authoring/authoring.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconverter_error_data_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_export\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtf_export\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_tf_export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph_pb2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_graph_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmicrofrontend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maudio_microfrontend_op\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlite_constants\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_toco_convert_protos\u001b[0m  \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/lite/experimental/microfrontend/python/ops/audio_microfrontend_op.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m _audio_microfrontend_op = load_library.load_op_library(\n\u001b[0;32m---> 30\u001b[0;31m     resource_loader.get_path_to_datafile(\"_audio_microfrontend_op.so\"))\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/load_library.py\u001b[0m in \u001b[0;36mload_op_library\u001b[0;34m(library_filename)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0munable\u001b[0m \u001b[0mto\u001b[0m \u001b[0mload\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlibrary\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpython\u001b[0m \u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m   \"\"\"\n\u001b[0;32m---> 58\u001b[0;31m   \u001b[0mlib_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_LoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     wrappers = _pywrap_python_op_gen.GetPythonWrappers(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "import itertools\n",
        " \n",
        "# Mengihitung waktu lamanya eksekusi tiap sel di Google Colab\n",
        "!pip install ipython-autotime\n",
        " \n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZU5Fqk2vLELg"
      },
      "source": [
        "## *Preprocessing* Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D48VICs21pna"
      },
      "outputs": [],
      "source": [
        "# Inisialisasi nilai Initial Learning Rate, berapa banyak Epoch pelatihan, dan Batch Size\n",
        "INIT_LR = 1e-4\n",
        "EPOCHS = 200\n",
        "BS = 32\n",
        " \n",
        "# Mengambil gambar dari dataset directory, kemudian inisialisasi data dan class gambar\n",
        "print(\"Menginput gambar...\")\n",
        "imagePaths = list(paths.list_images('dataset'))\n",
        "data = []\n",
        "labels = []\n",
        " \n",
        "# Melakukan perulangan pada image paths\n",
        "for imagePath in imagePaths:\n",
        " \n",
        "    # Mengekstrak class label dari filename\n",
        "    label = imagePath.split(os.path.sep)[-2]\n",
        "    # Memuat input gambar (224x224) dan melakukan proses\n",
        "    image = load_img(imagePath, target_size=(224, 224))\n",
        "    image = img_to_array(image)\n",
        "    image = preprocess_input(image)\n",
        " \n",
        "    # Mengupdate data dan labels lists, berurutan\n",
        "    data.append(image)\n",
        "    labels.append(label)\n",
        " \n",
        "# Mengkonversi data dan label ke dalam NumPy Arrays\n",
        "data = np.array(data, dtype=\"float32\")\n",
        "labels = np.array(labels)\n",
        " \n",
        "# Melakukan one-hot encoding on the labels\n",
        "lb = LabelBinarizer()\n",
        "labels = lb.fit_transform(labels)\n",
        "labels = to_categorical(labels)\n",
        "print(\"Input gambar berhasil\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF2vfrgni3tq"
      },
      "source": [
        "### Membuat objek ImageDataGenerator dan Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRBrygye5yvc",
        "outputId": "bc843ec5-6dec-4c61-ab6a-cfb23056f3e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 5.75 s (started: 2022-02-07 13:27:04 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Mempartisi data ke dalam pelatihan dan pengujian ( 75% : 25% )\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
        "    test_size=0.20, stratify=labels, random_state=42)\n",
        " \n",
        "# Membentuk training image generator untuk data augmentation\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHPD753f5205"
      },
      "source": [
        "## Membuat Model Jaringan CNN yang sudah dipelajari sebelumnya (*pre-trained convnets*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaDceTqP6HLr",
        "outputId": "b663cbaf-a421-444a-b69d-097f1920f0ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "time: 700 ms (started: 2022-02-07 13:27:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "# Arsitektur jaringan VGG16Net\n",
        "baseModel = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False,\n",
        "    input_tensor=Input(shape=(224, 224, 3)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfSLr2q2LWRZ"
      },
      "source": [
        "### *Feature Extraction*\n",
        "\n",
        "Menggunakan model *pre-trained* untuk ekstraksi fitur (*feature extraction*) : Ketika bekerja dengan dataset kecil, adalah umum untuk mengambil keuntungan dari fitur yang dipelajari oleh model yang dilatih pada dataset yang lebih besar dalam domain yang sama."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0U2qYnO6KYW",
        "outputId": "f82e0cf5-578f-4922-cba3-8787a75f6bd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 0\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "time: 31.7 ms (started: 2022-02-07 13:27:11 +00:00)\n"
          ]
        }
      ],
      "source": [
        "baseModel.trainable = False\n",
        "baseModel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENpg9P6Q6SpL"
      },
      "source": [
        "## Tahap Pembuatan Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXEyXB5NTU13",
        "outputId": "e2c47d8d-6599-4224-af89-284214847dd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mengkompilasi model...\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 1, 1, 512)        0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,780,610\n",
            "Trainable params: 65,922\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "time: 107 ms (started: 2022-02-07 13:27:11 +00:00)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Membentuk bagian head dari model yang akan ditempatkan pada base model\n",
        "headModel = baseModel.output\n",
        "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
        "headModel = Flatten(name=\"flatten\")(headModel)\n",
        "headModel = Dense(128, activation=\"relu\")(headModel)\n",
        "headModel = Dropout(0.5)(headModel)\n",
        "headModel = Dense(2, activation=\"softmax\")(headModel)\n",
        " \n",
        "# Menempatkan head model pada base model\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        " \n",
        "# Perulangan pada seluruh base model\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        " \n",
        "# Persiapan kompilasi model\n",
        "print(\"Mengkompilasi model...\")\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lH42Hp3UWrPs"
      },
      "source": [
        "### Melakukan Pelatihan Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZPSj-se6WdI",
        "outputId": "bc37fc43-8454-4896-96fd-712460ca374d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training head model...\n",
            "Epoch 1/20\n",
            "95/95 [==============================] - 1817s 19s/step - loss: 1.1080 - accuracy: 0.7169 - val_loss: 0.1825 - val_accuracy: 0.9518\n",
            "Epoch 2/20\n",
            "95/95 [==============================] - 1712s 18s/step - loss: 0.4042 - accuracy: 0.9011 - val_loss: 0.0852 - val_accuracy: 0.9791\n",
            "Epoch 3/20\n",
            " 4/95 [>.............................] - ETA: 21:44 - loss: 0.3549 - accuracy: 0.9062"
          ]
        }
      ],
      "source": [
        "# Pelatihan model\n",
        "print(\"Training head model...\")\n",
        "H = model.fit(\n",
        "    aug.flow(trainX, trainY, batch_size=BS),\n",
        "    steps_per_epoch=len(trainX) // BS,\n",
        "    validation_data=(testX, testY),\n",
        "    validation_steps=len(testX) // BS,\n",
        "    epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxqTwaGi7Wzs"
      },
      "source": [
        "### Menampilkan Grafik Model Hasil Pelatihan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OURpwhV87ac9"
      },
      "outputs": [],
      "source": [
        "# Grafik Akurasi\n",
        "N = EPOCHS\n",
        "fig = plt.figure(figsize=(7, 4))\n",
        "fig.set_figheight(10)\n",
        "fig.set_figwidth(15)\n",
        " \n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(np.arange(0, N), H.history[\"accuracy\"],label = \"Training Accuracy\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"],label = \"Validation Accuracy\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "# plt.title(\"Kurva Tingkat Akurasi\", size=15)\n",
        "plt.grid(zorder = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v9tUBpm9Xt3"
      },
      "outputs": [],
      "source": [
        "# Grafik error\n",
        "N = EPOCHS\n",
        "fig = plt.figure(figsize=(7, 4))\n",
        "fig.set_figheight(10)\n",
        "fig.set_figwidth(15)\n",
        " \n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"],label = \"Training Loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"],label = \"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Error\")\n",
        "# plt.title(\"Kurva Tingkat Error\", size=15)\n",
        "plt.grid(zorder = 0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mqe8nNB7lp8"
      },
      "source": [
        "### Evaluasi Jaringan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLxROO1pg7Em"
      },
      "outputs": [],
      "source": [
        "# Memeriksa matriks model\n",
        "print(model.metrics_names)\n",
        "# Evaluasi data test\n",
        "print(model.evaluate(x= testX, y = testY))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySJujhciZvlQ"
      },
      "outputs": [],
      "source": [
        "# Menampilkan matriks yang benar dan matriks hasil prediksi\n",
        "# Label yang benar\n",
        "yTrue = np.argmax(testY, axis=1)\n",
        "\n",
        "# Label prediksi\n",
        "YPred = model.predict(testX, batch_size=BS)\n",
        "yPred = np.argmax(YPred, axis=1)\n",
        "\n",
        "print(yTrue)\n",
        "print(yPred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl0Y-D41imCP"
      },
      "source": [
        "### *Confusion Matrix*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EL_ROzJdh6pm"
      },
      "outputs": [],
      "source": [
        "def get_confusion_matrix(yTrue, yPred):\n",
        "    n_classes = len(np.unique(yTrue)) \n",
        "    conf = np.zeros((n_classes, n_classes))\n",
        "    for actual, pred in zip(yTrue, yPred):\n",
        "        conf[int(actual)][int(pred)] += 1\n",
        "    return conf.astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxoC6xxjaCrf"
      },
      "outputs": [],
      "source": [
        "conf = get_confusion_matrix(yTrue, yPred)\n",
        "conf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ss9YmprkdirH"
      },
      "outputs": [],
      "source": [
        "classes = [0, 1]\n",
        "# Plot confusion matrix\n",
        "plt.imshow(conf, interpolation='nearest', cmap=plt.cm.Greens)\n",
        "# plt.title(\"Confusion Matrix\")\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes)\n",
        "plt.yticks(tick_marks, classes)\n",
        "\n",
        "fmt = 'd'\n",
        "thresh = conf.max() / 2.\n",
        "for i, j in itertools.product(range(conf.shape[0]), range(conf.shape[1])):\n",
        "    plt.text(j, i, format(conf[i, j], fmt),\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if conf[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Prediction Label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr58aW7Ui7PD"
      },
      "source": [
        "Analisis mAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Psuc1y0i_NJ"
      },
      "outputs": [],
      "source": [
        "# Berdasarkan confusion matrix\n",
        "TP = true_pos = 378\n",
        "TN = true_neg = 383\n",
        "FP = false_pos = 0\n",
        "FN = false_neg = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YorxeJVtj0tZ"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "\n",
        "# Akurasi\n",
        "metric = \"Akurasi\"\n",
        "results[metric] = (TP + TN) / (TP + TN + FP + FN)\n",
        "print(f\"{metric} = {results[metric]: .3f}\")\n",
        "\n",
        "# Recall\n",
        "metric = \"Recall\"\n",
        "results[metric] = TP / (TP + FN)\n",
        "print(f\"{metric} = {results[metric]: .3f}\")\n",
        "\n",
        "# Presisi\n",
        "metric = \"Presisi\"\n",
        "results[metric] = TP / (TP + FP)\n",
        "print(f\"{metric} = {results[metric]: .3f}\")\n",
        "\n",
        "# Nilai F1\n",
        "metric = \"F1\"\n",
        "results[metric] = 2 / (1 / results[\"Presisi\"] + 1 / results[\"Recall\"])\n",
        "print(f\"{metric} = {results[metric]: .3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDPEy5zamOoi"
      },
      "outputs": [],
      "source": [
        "# Membuat prediksi dari pengujian\n",
        "predIdxs = model.predict(testX, batch_size=BS)\n",
        " \n",
        "# Untuk setiap gambar dalam set pengujian, kita perlu menemukan indeks label\n",
        "# dengan probabilitas prediksi terbesar\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        " \n",
        "# Menampilkan laporan klasifikasi yang diformat dengan baik\n",
        "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
        "    target_names=lb.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8U7B1jv8ZQr"
      },
      "source": [
        "## Menyimpan dan Konversi Model ke \".tflite\"\n",
        "Menyimpan model menggunakan tf.saved_model/save dan kemudian mengkonversi model tersimpan ke format yang kompatibel tf lite."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTaHZm7mKjLK"
      },
      "outputs": [],
      "source": [
        "export_dir='saved_model/1'\n",
        "tf.saved_model.save(model, export_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQDDJ2eYKk21"
      },
      "outputs": [],
      "source": [
        "# Mengkonvert model ke format tflite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "tflite_model = converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZet8SWWKn_S"
      },
      "outputs": [],
      "source": [
        "# Menyimpan model\n",
        "tflite_model_file = pathlib.Path('model.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znn1rBf6Jcfu"
      },
      "outputs": [],
      "source": [
        "# Memuat model dan mengalokasikan ke tensor\n",
        "interpreter = tf.lite.Interpreter(model_content = tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Mendapatkan input dan ouput tensor\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "\n",
        "print(input_details)\n",
        "print(output_details)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-H94fpq_E0J"
      },
      "source": [
        "## Pengujian Model dengan SSD ResNet10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T0GaCA5_SRw"
      },
      "source": [
        "Model diujikan pada gambar dan secara real-time dengan menggunakan res10_300x300_ssd_iter_14000.caffemodel dan deploy.prototxt yang digunakan untuk mendeteksi wajah."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nej9QmRT8-DO"
      },
      "source": [
        "### Penggunaan Model pada Gambar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwPKPee0Qi3h"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkkXJ-MpKKSV"
      },
      "outputs": [],
      "source": [
        "image = cv2.imread('/content/face-mask-detection/example_img/h01.jpg')\n",
        "orig = image.copy()\n",
        "(h, w) = image.shape[:2]\n",
        "\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300),\n",
        "\t(104.0, 177.0, 123.0))\n",
        "\n",
        "net=cv2.dnn.readNet('/content/face-mask-detection/deploy.prototxt','/content/face-mask-detection/res10_300x300_ssd_iter_140000.caffemodel')\n",
        "\n",
        "# Melewatkan blob melalui jaringan dan mendapatkan deteksi wajah\n",
        "print(\"Mendeteksi wajah...\")\n",
        "net.setInput(blob)\n",
        "detections = net.forward()\n",
        "\n",
        "for i in range(0, detections.shape[2]):\n",
        "\t# ekstrak keyakinan (yaitu, probabilitas) yang terkait dengan deteksi\n",
        "\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\tif confidence > 0.5:\n",
        "\t\t# Menghitung koordinat (x, y) dari kotak pembatas untuk objek\n",
        "\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\t\t# Memastikan kotak pembatas berada dalam dimensi bingkai\n",
        "\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
        "\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
        "\n",
        "\t\t# Ekstrak ROI wajah, konversikan dari BGR ke pemesanan saluran RGB,\n",
        "    # dan mengubah ukurannya menjadi 224x224, dan lalu pre-proses\n",
        "\t\tface = image[startY:endY, startX:endX]\n",
        "\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\t\tface = cv2.resize(face, (224, 224))\n",
        "\t\tface = img_to_array(face)\n",
        "\t\tface = preprocess_input(face)\n",
        "\t\tface = np.expand_dims(face, axis=0)\n",
        "\n",
        "\t\t# Membaca wajah dengan model\n",
        "\t\t(mask, withoutMask) = model.predict(face)[0]\n",
        "\n",
        "\t\t# Menggunakan masker hijau, tidak bermasker merah\n",
        "\t\tlabel = \"Bermasker\" if mask > withoutMask else \"Tidak Bermasker\"\n",
        "\t\tcolor = (0, 255, 0) if label == \"Bermasker\" else (0, 0, 255)\n",
        "\n",
        "\t\t# Probabilitas hasil deteksi\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "\t\t# Menampilkan hasil dengan label dan kotak\n",
        "\t\tcv2.putText(image, label, (startX, startY - 10),\n",
        "\t\t\tcv2.FONT_HERSHEY_TRIPLEX, 0.45, color, 2)\n",
        "\t\tcv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
        "\n",
        "# Menampilkan output\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/content/face-mask-detection/example_img/h02.jpg')\n",
        "orig = image.copy()\n",
        "(h, w) = image.shape[:2]\n",
        "\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300),\n",
        "\t(104.0, 177.0, 123.0))\n",
        "\n",
        "net=cv2.dnn.readNet('/content/face-mask-detection/deploy.prototxt','/content/face-mask-detection/res10_300x300_ssd_iter_140000.caffemodel')\n",
        "\n",
        "# Melewatkan blob melalui jaringan dan mendapatkan deteksi wajah\n",
        "print(\"Mendeteksi wajah...\")\n",
        "net.setInput(blob)\n",
        "detections = net.forward()\n",
        "\n",
        "for i in range(0, detections.shape[2]):\n",
        "\t# ekstrak keyakinan (yaitu, probabilitas) yang terkait dengan deteksi\n",
        "\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\tif confidence > 0.5:\n",
        "\t\t# Menghitung koordinat (x, y) dari kotak pembatas untuk objek\n",
        "\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\t\t# Memastikan kotak pembatas berada dalam dimensi bingkai\n",
        "\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
        "\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
        "\n",
        "\t\t# Ekstrak ROI wajah, konversikan dari BGR ke pemesanan saluran RGB,\n",
        "    # dan mengubah ukurannya menjadi 224x224, dan lalu pre-proses\n",
        "\t\tface = image[startY:endY, startX:endX]\n",
        "\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\t\tface = cv2.resize(face, (224, 224))\n",
        "\t\tface = img_to_array(face)\n",
        "\t\tface = preprocess_input(face)\n",
        "\t\tface = np.expand_dims(face, axis=0)\n",
        "\n",
        "\t\t# Membaca wajah dengan model\n",
        "\t\t(mask, withoutMask) = model.predict(face)[0]\n",
        "\n",
        "\t\t# Menggunakan masker hijau, tidak bermasker merah\n",
        "\t\tlabel = \"Bermasker\" if mask > withoutMask else \"Tidak Bermasker\"\n",
        "\t\tcolor = (0, 255, 0) if label == \"Bermasker\" else (0, 0, 255)\n",
        "\n",
        "\t\t# Probabilitas hasil deteksi\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "\t\t# Menampilkan hasil dengan label dan kotak\n",
        "\t\tcv2.putText(image, label, (startX, startY - 10),\n",
        "\t\t\tcv2.FONT_HERSHEY_TRIPLEX, 0.45, color, 2)\n",
        "\t\tcv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
        "\n",
        "# Menampilkan output\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "Z4PO6wyLtdEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/content/face-mask-detection/example_img/h03.jpg')\n",
        "orig = image.copy()\n",
        "(h, w) = image.shape[:2]\n",
        "\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300),\n",
        "\t(104.0, 177.0, 123.0))\n",
        "\n",
        "net=cv2.dnn.readNet('/content/face-mask-detection/deploy.prototxt','/content/face-mask-detection/res10_300x300_ssd_iter_140000.caffemodel')\n",
        "\n",
        "# Melewatkan blob melalui jaringan dan mendapatkan deteksi wajah\n",
        "print(\"Mendeteksi wajah...\")\n",
        "net.setInput(blob)\n",
        "detections = net.forward()\n",
        "\n",
        "for i in range(0, detections.shape[2]):\n",
        "\t# ekstrak keyakinan (yaitu, probabilitas) yang terkait dengan deteksi\n",
        "\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\tif confidence > 0.5:\n",
        "\t\t# Menghitung koordinat (x, y) dari kotak pembatas untuk objek\n",
        "\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\t\t# Memastikan kotak pembatas berada dalam dimensi bingkai\n",
        "\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
        "\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
        "\n",
        "\t\t# Ekstrak ROI wajah, konversikan dari BGR ke pemesanan saluran RGB,\n",
        "    # dan mengubah ukurannya menjadi 224x224, dan lalu pre-proses\n",
        "\t\tface = image[startY:endY, startX:endX]\n",
        "\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\t\tface = cv2.resize(face, (224, 224))\n",
        "\t\tface = img_to_array(face)\n",
        "\t\tface = preprocess_input(face)\n",
        "\t\tface = np.expand_dims(face, axis=0)\n",
        "\n",
        "\t\t# Membaca wajah dengan model\n",
        "\t\t(mask, withoutMask) = model.predict(face)[0]\n",
        "\n",
        "\t\t# Menggunakan masker hijau, tidak bermasker merah\n",
        "\t\tlabel = \"Bermasker\" if mask > withoutMask else \"Tidak Bermasker\"\n",
        "\t\tcolor = (0, 255, 0) if label == \"Bermasker\" else (0, 0, 255)\n",
        "\n",
        "\t\t# Probabilitas hasil deteksi\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "\t\t# Menampilkan hasil dengan label dan kotak\n",
        "\t\tcv2.putText(image, label, (startX, startY - 10),\n",
        "\t\t\tcv2.FONT_HERSHEY_TRIPLEX, 0.45, color, 2)\n",
        "\t\tcv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
        "\n",
        "# Menampilkan output\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "bYNQQMXTthae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/content/face-mask-detection/example_img/h04.jpg')\n",
        "orig = image.copy()\n",
        "(h, w) = image.shape[:2]\n",
        "\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300),\n",
        "\t(104.0, 177.0, 123.0))\n",
        "\n",
        "net=cv2.dnn.readNet('/content/face-mask-detection/deploy.prototxt','/content/face-mask-detection/res10_300x300_ssd_iter_140000.caffemodel')\n",
        "\n",
        "# Melewatkan blob melalui jaringan dan mendapatkan deteksi wajah\n",
        "print(\"Mendeteksi wajah...\")\n",
        "net.setInput(blob)\n",
        "detections = net.forward()\n",
        "\n",
        "for i in range(0, detections.shape[2]):\n",
        "\t# ekstrak keyakinan (yaitu, probabilitas) yang terkait dengan deteksi\n",
        "\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\tif confidence > 0.5:\n",
        "\t\t# Menghitung koordinat (x, y) dari kotak pembatas untuk objek\n",
        "\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\t\t# Memastikan kotak pembatas berada dalam dimensi bingkai\n",
        "\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
        "\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
        "\n",
        "\t\t# Ekstrak ROI wajah, konversikan dari BGR ke pemesanan saluran RGB,\n",
        "    # dan mengubah ukurannya menjadi 224x224, dan lalu pre-proses\n",
        "\t\tface = image[startY:endY, startX:endX]\n",
        "\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\t\tface = cv2.resize(face, (224, 224))\n",
        "\t\tface = img_to_array(face)\n",
        "\t\tface = preprocess_input(face)\n",
        "\t\tface = np.expand_dims(face, axis=0)\n",
        "\n",
        "\t\t# Membaca wajah dengan model\n",
        "\t\t(mask, withoutMask) = model.predict(face)[0]\n",
        "\n",
        "\t\t# Menggunakan masker hijau, tidak bermasker merah\n",
        "\t\tlabel = \"Bermasker\" if mask > withoutMask else \"Tidak Bermasker\"\n",
        "\t\tcolor = (0, 255, 0) if label == \"Bermasker\" else (0, 0, 255)\n",
        "\n",
        "\t\t# Probabilitas hasil deteksi\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "\t\t# Menampilkan hasil dengan label dan kotak\n",
        "\t\tcv2.putText(image, label, (startX, startY - 10),\n",
        "\t\t\tcv2.FONT_HERSHEY_TRIPLEX, 0.45, color, 2)\n",
        "\t\tcv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
        "\n",
        "# Menampilkan output\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "HZgKiXiztjbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = cv2.imread('/content/face-mask-detection/example_img/h05.jpg')\n",
        "orig = image.copy()\n",
        "(h, w) = image.shape[:2]\n",
        "\n",
        "blob = cv2.dnn.blobFromImage(image, 1.0, (300, 300),\n",
        "\t(104.0, 177.0, 123.0))\n",
        "\n",
        "net=cv2.dnn.readNet('/content/face-mask-detection/deploy.prototxt','/content/face-mask-detection/res10_300x300_ssd_iter_140000.caffemodel')\n",
        "\n",
        "# Melewatkan blob melalui jaringan dan mendapatkan deteksi wajah\n",
        "print(\"Mendeteksi wajah...\")\n",
        "net.setInput(blob)\n",
        "detections = net.forward()\n",
        "\n",
        "for i in range(0, detections.shape[2]):\n",
        "\t# ekstrak keyakinan (yaitu, probabilitas) yang terkait dengan deteksi\n",
        "\tconfidence = detections[0, 0, i, 2]\n",
        "\n",
        "\tif confidence > 0.5:\n",
        "\t\t# Menghitung koordinat (x, y) dari kotak pembatas untuk objek\n",
        "\t\tbox = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "\t\t# Memastikan kotak pembatas berada dalam dimensi bingkai\n",
        "\t\t(startX, startY) = (max(0, startX), max(0, startY))\n",
        "\t\t(endX, endY) = (min(w - 1, endX), min(h - 1, endY))\n",
        "\n",
        "\t\t# Ekstrak ROI wajah, konversikan dari BGR ke pemesanan saluran RGB,\n",
        "    # dan mengubah ukurannya menjadi 224x224, dan lalu pre-proses\n",
        "\t\tface = image[startY:endY, startX:endX]\n",
        "\t\tface = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "\t\tface = cv2.resize(face, (224, 224))\n",
        "\t\tface = img_to_array(face)\n",
        "\t\tface = preprocess_input(face)\n",
        "\t\tface = np.expand_dims(face, axis=0)\n",
        "\n",
        "\t\t# Membaca wajah dengan model\n",
        "\t\t(mask, withoutMask) = model.predict(face)[0]\n",
        "\n",
        "\t\t# Menggunakan masker hijau, tidak bermasker merah\n",
        "\t\tlabel = \"Bermasker\" if mask > withoutMask else \"Tidak Bermasker\"\n",
        "\t\tcolor = (0, 255, 0) if label == \"Bermasker\" else (0, 0, 255)\n",
        "\n",
        "\t\t# Probabilitas hasil deteksi\n",
        "\t\tlabel = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "\t\t# Menampilkan hasil dengan label dan kotak\n",
        "\t\tcv2.putText(image, label, (startX, startY - 10),\n",
        "\t\t\tcv2.FONT_HERSHEY_TRIPLEX, 0.45, color, 2)\n",
        "\t\tcv2.rectangle(image, (startX, startY), (endX, endY), color, 2)\n",
        "\n",
        "# Menampilkan output\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "sMFFUPZatpOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzfvwY4fRGHy"
      },
      "source": [
        "## Pengujian dengan Model MTCNN\n",
        "Model diujikan pada gambar dan secara real-time dengan menggunakan MTCNN yang digunakan untuk mendeteksi wajah."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1EB6Qz0gVhD"
      },
      "outputs": [],
      "source": [
        "!pip install mtcnn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIQu5R6ngXoj"
      },
      "source": [
        "### Pengujian Model dengan Gambar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKRyZAQJgjVP"
      },
      "outputs": [],
      "source": [
        "from mtcnn import MTCNN\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgzaTp4sgj3f"
      },
      "outputs": [],
      "source": [
        "detector = MTCNN()\n",
        "image = cv2.imread('/content/face-mask-detection/example_img/h01.jpg', cv2.COLOR_BGR2RGB)\n",
        "faces = detector.detect_faces(image)\n",
        "for result in faces:\n",
        "    x, y, w, h = result['box']\n",
        "    x1, y1 = x + w, y + h\n",
        "    \n",
        "    # Ekstrak ROI wajah, konversikan dari BGR ke pemesanan saluran RGB,\n",
        "    # dan mengubah ukurannya menjadi 224x224, dan lalu pre-proses\n",
        "    face = image[y:y1, x:x1]\n",
        "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "    face = cv2.resize(face, (224, 224))\n",
        "    face = img_to_array(face)\n",
        "    face = preprocess_input(face)\n",
        "    face = np.expand_dims(face, axis=0)    \n",
        "\n",
        "    # Membaca wajah dengan model\n",
        "    (mask, withoutMask) = model.predict(face)[0]\n",
        "\n",
        "    # Menggunakan masker hijau, tidak bermasker merah\n",
        "    label = \"Bermasker\" if mask > withoutMask else \"Tidak Bermasker\"\n",
        "    color = (0, 255, 0) if label == \"Bermasker\" else (0, 0, 255)\n",
        "\n",
        "\t\t# Probabilitas hasil deteksi\n",
        "    label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "    # Menampilkan hasil dengan label dan kotak\n",
        "    cv2.putText(image, label, (x, y - 10),\n",
        "    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "    cv2.rectangle(image, (x, y), (x1, y1), color, 2)\n",
        "\n",
        "# Menampilkan output\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detector = MTCNN()\n",
        "image = cv2.imread('/content/face-mask-detection/example_img/h02.jpg', cv2.COLOR_BGR2RGB)\n",
        "faces = detector.detect_faces(image)\n",
        "for result in faces:\n",
        "    x, y, w, h = result['box']\n",
        "    x1, y1 = x + w, y + h\n",
        "    \n",
        "    # Ekstrak ROI wajah, konversikan dari BGR ke pemesanan saluran RGB,\n",
        "    # dan mengubah ukurannya menjadi 224x224, dan lalu pre-proses\n",
        "    face = image[y:y1, x:x1]\n",
        "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "    face = cv2.resize(face, (224, 224))\n",
        "    face = img_to_array(face)\n",
        "    face = preprocess_input(face)\n",
        "    face = np.expand_dims(face, axis=0)    \n",
        "\n",
        "    # Membaca wajah dengan model\n",
        "    (mask, withoutMask) = model.predict(face)[0]\n",
        "\n",
        "    # Menggunakan masker hijau, tidak bermasker merah\n",
        "    label = \"Bermasker\" if mask > withoutMask else \"Tidak Bermasker\"\n",
        "    color = (0, 255, 0) if label == \"Bermasker\" else (0, 0, 255)\n",
        "\n",
        "\t\t# Probabilitas hasil deteksi\n",
        "    label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "    # Menampilkan hasil dengan label dan kotak\n",
        "    cv2.putText(image, label, (x, y - 10),\n",
        "    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "    cv2.rectangle(image, (x, y), (x1, y1), color, 2)\n",
        "\n",
        "# Menampilkan output\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "CY5Oq4NNtPX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = MTCNN()\n",
        "image = cv2.imread('/content/face-mask-detection/example_img/h03.jpg', cv2.COLOR_BGR2RGB)\n",
        "faces = detector.detect_faces(image)\n",
        "for result in faces:\n",
        "    x, y, w, h = result['box']\n",
        "    x1, y1 = x + w, y + h\n",
        "    \n",
        "    # Ekstrak ROI wajah, konversikan dari BGR ke pemesanan saluran RGB,\n",
        "    # dan mengubah ukurannya menjadi 224x224, dan lalu pre-proses\n",
        "    face = image[y:y1, x:x1]\n",
        "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "    face = cv2.resize(face, (224, 224))\n",
        "    face = img_to_array(face)\n",
        "    face = preprocess_input(face)\n",
        "    face = np.expand_dims(face, axis=0)    \n",
        "\n",
        "    # Membaca wajah dengan model\n",
        "    (mask, withoutMask) = model.predict(face)[0]\n",
        "\n",
        "    # Menggunakan masker hijau, tidak bermasker merah\n",
        "    label = \"Bermasker\" if mask > withoutMask else \"Tidak Bermasker\"\n",
        "    color = (0, 255, 0) if label == \"Bermasker\" else (0, 0, 255)\n",
        "\n",
        "\t\t# Probabilitas hasil deteksi\n",
        "    label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "    # Menampilkan hasil dengan label dan kotak\n",
        "    cv2.putText(image, label, (x, y - 10),\n",
        "    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "    cv2.rectangle(image, (x, y), (x1, y1), color, 2)\n",
        "\n",
        "# Menampilkan output\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "XfSQ3pn0twLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = MTCNN()\n",
        "image = cv2.imread('/content/face-mask-detection/example_img/h04.jpg', cv2.COLOR_BGR2RGB)\n",
        "faces = detector.detect_faces(image)\n",
        "for result in faces:\n",
        "    x, y, w, h = result['box']\n",
        "    x1, y1 = x + w, y + h\n",
        "    \n",
        "    # Ekstrak ROI wajah, konversikan dari BGR ke pemesanan saluran RGB,\n",
        "    # dan mengubah ukurannya menjadi 224x224, dan lalu pre-proses\n",
        "    face = image[y:y1, x:x1]\n",
        "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "    face = cv2.resize(face, (224, 224))\n",
        "    face = img_to_array(face)\n",
        "    face = preprocess_input(face)\n",
        "    face = np.expand_dims(face, axis=0)    \n",
        "\n",
        "    # Membaca wajah dengan model\n",
        "    (mask, withoutMask) = model.predict(face)[0]\n",
        "\n",
        "    # Menggunakan masker hijau, tidak bermasker merah\n",
        "    label = \"Bermasker\" if mask > withoutMask else \"Tidak Bermasker\"\n",
        "    color = (0, 255, 0) if label == \"Bermasker\" else (0, 0, 255)\n",
        "\n",
        "\t\t# Probabilitas hasil deteksi\n",
        "    label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "    # Menampilkan hasil dengan label dan kotak\n",
        "    cv2.putText(image, label, (x, y - 10),\n",
        "    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "    cv2.rectangle(image, (x, y), (x1, y1), color, 2)\n",
        "\n",
        "# Menampilkan output\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "L8nQRzbctxw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "detector = MTCNN()\n",
        "image = cv2.imread('/content/face-mask-detection/example_img/h05.jpg', cv2.COLOR_BGR2RGB)\n",
        "faces = detector.detect_faces(image)\n",
        "for result in faces:\n",
        "    x, y, w, h = result['box']\n",
        "    x1, y1 = x + w, y + h\n",
        "    \n",
        "    # Ekstrak ROI wajah, konversikan dari BGR ke pemesanan saluran RGB,\n",
        "    # dan mengubah ukurannya menjadi 224x224, dan lalu pre-proses\n",
        "    face = image[y:y1, x:x1]\n",
        "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "    face = cv2.resize(face, (224, 224))\n",
        "    face = img_to_array(face)\n",
        "    face = preprocess_input(face)\n",
        "    face = np.expand_dims(face, axis=0)    \n",
        "\n",
        "    # Membaca wajah dengan model\n",
        "    (mask, withoutMask) = model.predict(face)[0]\n",
        "\n",
        "    # Menggunakan masker hijau, tidak bermasker merah\n",
        "    label = \"Bermasker\" if mask > withoutMask else \"Tidak Bermasker\"\n",
        "    color = (0, 255, 0) if label == \"Bermasker\" else (0, 0, 255)\n",
        "\n",
        "\t\t# Probabilitas hasil deteksi\n",
        "    label = \"{}: {:.2f}%\".format(label, max(mask, withoutMask) * 100)\n",
        "\n",
        "    # Menampilkan hasil dengan label dan kotak\n",
        "    cv2.putText(image, label, (x, y - 10),\n",
        "    cv2.FONT_HERSHEY_SIMPLEX, 0.45, color, 2)\n",
        "    cv2.rectangle(image, (x, y), (x1, y1), color, 2)\n",
        "\n",
        "# Menampilkan output\n",
        "cv2_imshow(image)\n",
        "cv2.waitKey(0)"
      ],
      "metadata": {
        "id": "AHdCYV5Ztzd_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Salinan dari Face Mask Detection VGG16Net.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}